import os
import requests
import json
import time
import secrets
from fastapi import FastAPI, Header, HTTPException, Depends, status
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
from pypdf import PdfReader 
from typing import Optional

# ğŸš€ .env áƒ¤áƒáƒ˜áƒšáƒ˜áƒ¡ áƒ©áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒ•áƒ
from dotenv import load_dotenv 
load_dotenv() 

# ğŸ”‘ áƒ’áƒáƒ¡áƒáƒ¦áƒ”áƒ‘áƒ”áƒ‘áƒ˜áƒ¡ áƒ¬áƒáƒ™áƒ˜áƒ—áƒ®áƒ•áƒ áƒ’áƒáƒ áƒ”áƒ›áƒáƒ¡ áƒªáƒ•áƒšáƒáƒ“áƒ”áƒ‘áƒ˜áƒ“áƒáƒœ (áƒ£áƒ¡áƒáƒ¤áƒ áƒ—áƒ®áƒáƒ”áƒ‘áƒ!)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") 
LOCAL_API_KEY = os.getenv("LOCAL_API_KEY") # áƒ”áƒ¡ áƒªáƒ•áƒšáƒáƒ“áƒ˜ áƒáƒ¦áƒáƒ  áƒ’áƒáƒ›áƒáƒ˜áƒ§áƒ”áƒœáƒ”áƒ‘áƒ áƒ”áƒœáƒ“áƒ¤áƒáƒ˜áƒœáƒ¢áƒ˜áƒ¡ áƒáƒ•áƒ¢áƒáƒ áƒ˜áƒ–áƒáƒªáƒ˜áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡

# --- RAG áƒ˜áƒœáƒ¡áƒ¢áƒ áƒ£áƒ›áƒ”áƒœáƒ¢áƒ”áƒ‘áƒ˜áƒ¡ áƒ˜áƒ›áƒáƒáƒ áƒ¢áƒ˜ (OpenAI-áƒ¡áƒ—áƒ•áƒ˜áƒ¡) ---
RAG_TOOLS_AVAILABLE = False
try:
    if OPENAI_API_KEY:
        os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY 
        
        from langchain_openai import OpenAIEmbeddings
        from langchain_community.vectorstores import Chroma 
        from langchain_core.documents import Document
        RAG_TOOLS_AVAILABLE = True
        print("âœ… RAG áƒ‘áƒ˜áƒ‘áƒšáƒ˜áƒáƒ—áƒ”áƒ™áƒ”áƒ‘áƒ˜ áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ— áƒ©áƒáƒ˜áƒ¢áƒ•áƒ˜áƒ áƒ—áƒ.")
    else:
        print("âŒ WARNING: OPENAI_API_KEY áƒ•áƒ”áƒ  áƒ˜áƒ¥áƒœáƒ áƒœáƒáƒáƒáƒ•áƒœáƒ˜. RAG áƒ¤áƒ£áƒœáƒ¥áƒªáƒ˜áƒ”áƒ‘áƒ˜ áƒ’áƒáƒ›áƒáƒ áƒ—áƒ£áƒšáƒ˜áƒ.")
except ImportError as e:
    print(f"âŒ WARNING: RAG áƒ‘áƒ˜áƒ‘áƒšáƒ˜áƒáƒ—áƒ”áƒ™áƒ”áƒ‘áƒ˜áƒ¡ áƒ˜áƒ›áƒáƒáƒ áƒ¢áƒ˜áƒ¡ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒáƒ: {e}. RAG áƒ¤áƒ£áƒœáƒ¥áƒªáƒ˜áƒ”áƒ‘áƒ˜ áƒ’áƒáƒ›áƒáƒ áƒ—áƒ£áƒšáƒ˜áƒ.")

# --- áƒ™áƒáƒœáƒ¤áƒ˜áƒ’áƒ£áƒ áƒáƒªáƒ˜áƒ ---
API_KEY_NAME = "X-API-Key" # áƒáƒ¦áƒáƒ  áƒ’áƒáƒ›áƒáƒ˜áƒ§áƒ”áƒœáƒ”áƒ‘áƒ /process_query-áƒ–áƒ”

# OpenAI API áƒ“áƒ RAG áƒáƒáƒ áƒáƒ›áƒ”áƒ¢áƒ áƒ”áƒ‘áƒ˜
OPENAI_MODEL_NAME = "gpt-4o-mini"
OPENAI_API_URL = "https://api.openai.com/v1/chat/completions" 
PERSONA_PDF_PATH = "prompt.pdf"
CHROMA_PATH = "chroma_db"  

# áƒ’áƒšáƒáƒ‘áƒáƒšáƒ£áƒ áƒ˜ áƒáƒ‘áƒ˜áƒ”áƒ¥áƒ¢áƒ”áƒ‘áƒ˜
global_rag_retriever: Optional[Chroma.as_retriever] = None

# --- áƒ¤áƒ£áƒœáƒ¥áƒªáƒ˜áƒ áƒáƒ”áƒ áƒ¡áƒáƒœáƒ˜áƒ¡ PDF-áƒ“áƒáƒœ áƒ©áƒáƒ¡áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒáƒ“ ---
def load_persona_from_pdf(file_path: str) -> str:
    """áƒ™áƒ˜áƒ—áƒ®áƒ£áƒšáƒáƒ‘áƒ¡ áƒ›áƒ—áƒ”áƒš áƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ¡ PDF áƒ¤áƒáƒ˜áƒšáƒ˜áƒ“áƒáƒœ pypdf-áƒ˜áƒ¡ áƒ’áƒáƒ›áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ˜áƒ—."""
    DEFAULT_PERSONA = "áƒ—áƒ¥áƒ•áƒ”áƒœ áƒ®áƒáƒ áƒ— áƒ¡áƒáƒ¡áƒáƒ áƒ’áƒ”áƒ‘áƒšáƒ áƒáƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒœáƒ¢áƒ˜, áƒ áƒáƒ›áƒ”áƒšáƒ˜áƒª áƒáƒáƒ¡áƒ£áƒ®áƒáƒ‘áƒ¡ áƒ¥áƒáƒ áƒ—áƒ£áƒš áƒ”áƒœáƒáƒ–áƒ”."
    try:
        reader = PdfReader(file_path)
        text = "".join(page.extract_text() + "\n\n" for page in reader.pages if page.extract_text())
        
        if not text.strip():
            print(f"âŒ ERROR: PDF áƒ¤áƒáƒ˜áƒšáƒ˜ '{file_path}' áƒªáƒáƒ áƒ˜áƒ”áƒšáƒ˜áƒ. áƒ’áƒáƒ›áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ£áƒšáƒ˜áƒ áƒ“áƒ”áƒ¤áƒáƒšáƒ¢áƒ£áƒ áƒ˜ áƒáƒ”áƒ áƒ¡áƒáƒœáƒ.")
            return DEFAULT_PERSONA
            
        print(f"âœ… áƒáƒ”áƒ áƒ¡áƒáƒœáƒ˜áƒ¡ áƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜ áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ— áƒ©áƒáƒ˜áƒ¢áƒ•áƒ˜áƒ áƒ—áƒ {file_path}-áƒ“áƒáƒœ. áƒ¡áƒ˜áƒ’áƒ áƒ«áƒ”: {len(text.strip())} áƒ¡áƒ˜áƒ›áƒ‘áƒáƒšáƒ.")
        return text.strip()
    except Exception as e:
        print(f"âŒ ERROR: áƒáƒ”áƒ áƒ¡áƒáƒœáƒ˜áƒ¡ PDF-áƒ˜áƒ¡ áƒ¬áƒáƒ™áƒ˜áƒ—áƒ®áƒ•áƒ˜áƒ¡áƒáƒ¡ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {e}. áƒ’áƒáƒ›áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ£áƒšáƒ˜áƒ áƒ“áƒ”áƒ¤áƒáƒšáƒ¢áƒ£áƒ áƒ˜ áƒáƒ”áƒ áƒ¡áƒáƒœáƒ.")
        return DEFAULT_PERSONA

CUSTOM_PERSONA_TEXT = load_persona_from_pdf(PERSONA_PDF_PATH)

# --- FastAPI áƒáƒáƒšáƒ˜áƒ™áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ ---
app = FastAPI(title="OpenAI RAG API", version="1.0 - GPT Activated")

# --- Startup áƒšáƒáƒ’áƒ˜áƒ™áƒ: RAG áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ ---
@app.on_event("startup")
async def startup_event():
    global global_rag_retriever
    
    if not RAG_TOOLS_AVAILABLE:
        print("RAG áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ áƒ’áƒáƒ›áƒáƒ¢áƒáƒ•áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ.")
        return
        
    print(">>> RAG áƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒ›áƒ˜áƒ¡ áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ (OpenAI)...")
    
    if os.path.exists(CHROMA_PATH):
        try:
            # 1. Embedding áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ©áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒ•áƒ (OpenAI-áƒ¡áƒ—áƒ•áƒ˜áƒ¡)
            embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
            
            # 2. ChromaDB-áƒ˜áƒ¡ áƒ©áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒ•áƒ
            vector_store = Chroma(
                persist_directory=CHROMA_PATH, 
                embedding_function=embeddings
            )
            # 3. Retriever-áƒ˜áƒ¡ áƒ¨áƒ”áƒ¥áƒ›áƒœáƒ (áƒ™áƒáƒœáƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜áƒ¡ áƒáƒ›áƒáƒ¡áƒáƒ¦áƒ”áƒ‘áƒáƒ“)
            global_rag_retriever = vector_store.as_retriever(search_kwargs={"k": 3})
            print(f"âœ… RAG Retriever áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ— áƒ©áƒáƒ˜áƒ¢áƒ•áƒ˜áƒ áƒ—áƒ {CHROMA_PATH}-áƒ“áƒáƒœ.")
        except Exception as e:
            print(f"âŒ ERROR: ChromaDB-áƒ˜áƒ¡ áƒ©áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒ•áƒ áƒ•áƒ”áƒ  áƒ›áƒáƒ®áƒ”áƒ áƒ®áƒ“áƒ: {e}. áƒ¨áƒ”áƒáƒ›áƒáƒ¬áƒ›áƒ”áƒ— OPENAI_API_KEY.")
    else:
        print(f"âš ï¸ WARNING: áƒ•áƒ”áƒ¥áƒ¢áƒáƒ áƒ£áƒšáƒ˜ áƒ‘áƒáƒ–áƒ {CHROMA_PATH} áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ. RAG áƒáƒ áƒáƒáƒ¥áƒ¢áƒ˜áƒ£áƒ áƒ˜áƒ. áƒ’áƒáƒ£áƒ¨áƒ•áƒ˜áƒ— 'python ingest.py'")
        
# --- CORS Middleware áƒ“áƒáƒ›áƒáƒ¢áƒ”áƒ‘áƒ ---
origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸ›‘ áƒáƒ›áƒáƒ¦áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ: verify_api_key áƒ¤áƒ£áƒœáƒ¥áƒªáƒ˜áƒ

# áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒ›áƒáƒ“áƒ”áƒšáƒ”áƒ‘áƒ˜
class ChatbotRequest(BaseModel):
    prompt: str
    user_id: str

class ChatbotResponse(BaseModel):
    status: str
    processed_prompt: str
    ai_response: str
    result_data: dict

# --- OpenAI API-áƒ¡ áƒ’áƒáƒ›áƒáƒ«áƒáƒ®áƒ”áƒ‘áƒ (RAG áƒšáƒáƒ’áƒ˜áƒ™áƒ˜áƒ—) ---
def generate_openai_content(prompt: str) -> str:
    """áƒ£áƒ™áƒáƒ•áƒ¨áƒ˜áƒ áƒ“áƒ”áƒ‘áƒ OpenAI API-áƒ¡, áƒ˜áƒ§áƒ”áƒœáƒ”áƒ‘áƒ¡ RAG-áƒ¡ áƒ™áƒáƒœáƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜áƒ¡ áƒ“áƒáƒ¡áƒáƒ›áƒáƒ¢áƒ”áƒ‘áƒšáƒáƒ“."""
    if not OPENAI_API_KEY:
        return "ERROR: OPENAI API áƒ’áƒáƒ¡áƒáƒ¦áƒ”áƒ‘áƒ˜ áƒáƒ™áƒšáƒ˜áƒ áƒ’áƒáƒ áƒ”áƒ›áƒáƒ¡ áƒªáƒ•áƒšáƒáƒ“áƒ”áƒ‘áƒ¨áƒ˜."
    
    rag_context = ""
    is_rag_active = global_rag_retriever is not None
    
    if is_rag_active:
        try:
            # .invoke() áƒ›áƒ”áƒ—áƒáƒ“áƒ˜áƒ¡ áƒ’áƒáƒ›áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ
            docs: list[Document] = global_rag_retriever.invoke(prompt) 
            context_text = "\n---\n".join([doc.page_content for doc in docs])
            
            rag_context = (
                f"áƒ’áƒáƒ›áƒáƒ˜áƒ§áƒ”áƒœáƒ”áƒ— áƒ¨áƒ”áƒ›áƒ“áƒ”áƒ’áƒ˜ áƒ™áƒáƒœáƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜ áƒáƒáƒ¡áƒ£áƒ®áƒ˜áƒ¡ áƒ’áƒáƒ¡áƒáƒªáƒ”áƒ›áƒáƒ“. áƒ—áƒ£ áƒáƒáƒ¡áƒ£áƒ®áƒ˜ áƒ›áƒáƒªáƒ”áƒ›áƒ£áƒš áƒ™áƒáƒœáƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ¨áƒ˜ áƒáƒ  áƒáƒ áƒ˜áƒ¡, "
                f"áƒ›áƒáƒ¨áƒ˜áƒœ áƒ£áƒáƒáƒ¡áƒ£áƒ®áƒ”áƒ— áƒ–áƒáƒ’áƒáƒ“áƒ˜ áƒªáƒáƒ“áƒœáƒ˜áƒ¡ áƒ¡áƒáƒ¤áƒ£áƒ«áƒ•áƒ”áƒšáƒ–áƒ”: \n\n--- DOCUMENTS ---\n{context_text}\n---"
            )
            print(f"ğŸ” RAG-áƒ›áƒ áƒ˜áƒáƒáƒ•áƒ {len(docs)} áƒ áƒ”áƒšáƒ”áƒ•áƒáƒœáƒ¢áƒ£áƒ áƒ˜ áƒ¤áƒ áƒáƒ’áƒ›áƒ”áƒœáƒ¢áƒ˜.")
            
        except Exception as e:
            print(f"âŒ ERROR: RAG Retrieval-áƒ˜áƒ¡ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {e}")
            rag_context = ""

    final_user_prompt = f"{rag_context}\n\náƒ›áƒáƒ›áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒšáƒ˜áƒ¡ áƒ¨áƒ”áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ: {prompt}"

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {OPENAI_API_KEY}" 
    }
    
    payload = {
        "model": OPENAI_MODEL_NAME,
        "messages": [
            {"role": "system", "content": f"{CUSTOM_PERSONA_TEXT}"},
            {"role": "user", "content": final_user_prompt}
        ]
    }

    # API-áƒ¡ áƒ’áƒáƒ›áƒáƒ«áƒáƒ®áƒ”áƒ‘áƒ áƒ”áƒ¥áƒ¡áƒáƒáƒœáƒ”áƒœáƒªáƒ˜áƒáƒšáƒ£áƒ áƒ˜ Backoff-áƒ˜áƒ—
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = requests.post(
                OPENAI_API_URL, 
                headers=headers, 
                data=json.dumps(payload),
                timeout=30  
            )
            
            if response.status_code >= 400:
                try:
                    error_detail = response.json()
                    return f"ERROR: OpenAI API-áƒ› áƒ“áƒáƒáƒ‘áƒ áƒ£áƒœáƒ {response.status_code} áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ. áƒ“áƒ”áƒ¢áƒáƒšáƒ”áƒ‘áƒ˜: {error_detail.get('error', {}).get('message', 'áƒ“áƒ”áƒ¢áƒáƒšáƒ£áƒ áƒ˜ áƒ¨áƒ”áƒ¢áƒ§áƒáƒ‘áƒ˜áƒœáƒ”áƒ‘áƒ áƒ•áƒ”áƒ  áƒ›áƒ˜áƒ˜áƒ¦áƒ”áƒ¡.')}"
                except json.JSONDecodeError:
                    return f"ERROR: OpenAI API-áƒ› áƒ“áƒáƒáƒ‘áƒ áƒ£áƒœáƒ {response.status_code} áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ. áƒáƒáƒ¡áƒ£áƒ®áƒ˜ áƒáƒ  áƒáƒ áƒ˜áƒ¡ JSON-áƒ¨áƒ˜."
            
            response.raise_for_status() 
            result = response.json()
            
            if result.get('choices'):
                return result['choices'][0]['message']['content']
            
            return f"OpenAI API-áƒ› áƒ“áƒáƒáƒ‘áƒ áƒ£áƒœáƒ áƒáƒ áƒáƒ¡áƒ¢áƒáƒœáƒ“áƒáƒ áƒ¢áƒ£áƒšáƒ˜ áƒáƒáƒ¡áƒ£áƒ®áƒ˜."

        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt
                print(f"âš ï¸ Warning: OpenAI API-áƒ¡áƒ—áƒáƒœ áƒ“áƒáƒ™áƒáƒ•áƒ¨áƒ˜áƒ áƒ”áƒ‘áƒ áƒ•áƒ”áƒ  áƒ›áƒáƒ®áƒ”áƒ áƒ®áƒ“áƒ. áƒªáƒ“áƒ {attempt + 1}/{max_retries}. áƒšáƒáƒ“áƒ˜áƒœáƒ˜ {wait_time} áƒ¬áƒ›.")
                time.sleep(wait_time)
            else:
                return f"ERROR: OpenAI API-áƒ¡áƒ—áƒáƒœ áƒ“áƒáƒ™áƒáƒ•áƒ¨áƒ˜áƒ áƒ”áƒ‘áƒ áƒ•áƒ”áƒ  áƒ›áƒáƒ®áƒ”áƒ áƒ®áƒ“áƒ. áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {e}"
        except Exception as e:
            return f"ERROR: áƒ›áƒáƒ£áƒšáƒáƒ“áƒœáƒ”áƒšáƒ˜ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {e}"
    
    return "ERROR: áƒáƒáƒ¡áƒ£áƒ®áƒ˜ áƒ•áƒ”áƒ  áƒ˜áƒ¥áƒœáƒ áƒ’áƒ”áƒœáƒ”áƒ áƒ˜áƒ áƒ”áƒ‘áƒ£áƒšáƒ˜."


@app.get("/")
def read_root():
    rag_status = "áƒáƒ¥áƒ¢áƒ˜áƒ£áƒ áƒ˜áƒ" if global_rag_retriever else "áƒáƒ áƒáƒáƒ¥áƒ¢áƒ˜áƒ£áƒ áƒ˜áƒ (áƒ’áƒáƒ£áƒ¨áƒ•áƒ˜áƒ— ingest.py)"
    # áƒ¨áƒ”áƒ›áƒáƒ¬áƒ›áƒ”áƒ‘áƒ áƒáƒ®áƒšáƒ áƒ›áƒ®áƒáƒšáƒáƒ“ OPENAI_API_KEY-áƒ–áƒ”áƒ, áƒ áƒáƒ“áƒ’áƒáƒœ LOCAL_API_KEY áƒáƒ¦áƒáƒ  áƒáƒ áƒ˜áƒ¡ áƒ¡áƒáƒ•áƒáƒšáƒ“áƒ”áƒ‘áƒ£áƒšáƒ áƒ™áƒšáƒ˜áƒ”áƒœáƒ¢áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡
    config_ok = "âœ…" if OPENAI_API_KEY else "âŒ (OPENAI API áƒ’áƒáƒ¡áƒáƒ¦áƒ”áƒ‘áƒ˜ áƒáƒ™áƒšáƒ˜áƒ!)"
    return {"message": "API áƒ›áƒ£áƒ¨áƒáƒáƒ‘áƒ¡!", "Configuration_Status": config_ok, "RAG_Status": rag_status, "model": OPENAI_MODEL_NAME}

# ğŸ›‘ /process_query áƒ”áƒœáƒ“áƒ¤áƒáƒ˜áƒœáƒ¢áƒ˜ áƒáƒ¦áƒáƒ  áƒ¡áƒáƒ­áƒ˜áƒ áƒáƒ”áƒ‘áƒ¡ áƒáƒ•áƒ¢áƒáƒ áƒ˜áƒ–áƒáƒªáƒ˜áƒ˜áƒ¡ Header-áƒ¡ áƒ™áƒšáƒ˜áƒ”áƒœáƒ¢áƒ˜áƒ¡áƒ’áƒáƒœ
@app.post("/process_query", response_model=ChatbotResponse, tags=["Secured"])
async def process_query(
    request_data: ChatbotRequest,
    # âŒ áƒáƒ›áƒáƒ¦áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ: api_key: str = Depends(verify_api_key)
):
    openai_response = generate_openai_content(request_data.prompt)
    
    response_data = {
        "user": request_data.user_id,
        "length": len(request_data.prompt),
        "is_rag_active": global_rag_retriever is not None,
        "openai_model": OPENAI_MODEL_NAME
    }
    
    return ChatbotResponse(
        status="success",
        processed_prompt=f"áƒ—áƒ¥áƒ•áƒ”áƒœáƒ˜ áƒ›áƒáƒ—áƒ®áƒáƒ•áƒœáƒ áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ. áƒ¡áƒ˜áƒ’áƒ áƒ«áƒ”: {len(request_data.prompt)}.",
        ai_response=openai_response,
        result_data=response_data,
    )

if __name__ == "__main__":
    PORT = int(os.getenv("PORT", 8040))
    print(f"ğŸš€ áƒáƒáƒšáƒ˜áƒ™áƒáƒªáƒ˜áƒ áƒ˜áƒ¨áƒ•áƒ”áƒ‘áƒ: http://0.0.0.0:{PORT}")
    uvicorn.run(app, host="0.0.0.0", port=PORT)

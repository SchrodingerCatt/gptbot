import os
import uvicorn
from fastapi import FastAPI, Depends, HTTPException, status
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import CharacterTextSplitter
from fastapi.staticfiles import StaticFiles

# -------------------------------------------------------------
# 1. OpenAI API áƒ’áƒáƒ¡áƒáƒ¦áƒ”áƒ‘áƒ˜áƒ¡ áƒ¨áƒ”áƒ›áƒáƒ¬áƒ›áƒ”áƒ‘áƒ
# -------------------------------------------------------------

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    # áƒšáƒáƒ’áƒ˜áƒ áƒ”áƒ‘áƒ, áƒ—áƒ£ áƒ’áƒáƒ¡áƒáƒ¦áƒ”áƒ‘áƒ˜ áƒáƒ  áƒáƒ áƒ˜áƒ¡ áƒœáƒáƒáƒáƒ•áƒœáƒ˜
    print("FATAL: OPENAI_API_KEY áƒ’áƒáƒ áƒ”áƒ›áƒáƒ¡ áƒªáƒ•áƒšáƒáƒ“áƒ˜ áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ!")

# -------------------------------------------------------------
# 2. RAG áƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒ›áƒ˜áƒ¡ áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ
# -------------------------------------------------------------

vector_store = None
rag_chain = None

def init_rag_system():
    global vector_store, rag_chain
    try:
        # áƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜áƒ¡ áƒ©áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒ•áƒ PDF-áƒ“áƒáƒœ
        loader = PyPDFLoader("prompt.pdf")
        documents = loader.load()
        print(f"áƒáƒ”áƒ áƒ¡áƒáƒœáƒ˜áƒ¡ áƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜ áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ— áƒ©áƒáƒ˜áƒ¢áƒ•áƒ˜áƒ áƒ—áƒ prompt.pdf-áƒ“áƒáƒœ. áƒ¡áƒ˜áƒ’áƒ áƒ«áƒ”: {sum(len(doc.page_content) for doc in documents)} áƒ¡áƒ˜áƒ›áƒ‘áƒáƒšáƒ.")
        
        # áƒ“áƒáƒ™áƒ£áƒ›áƒ”áƒœáƒ¢áƒ˜áƒ¡ áƒ“áƒáƒ§áƒáƒ¤áƒ
        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
        texts = text_splitter.split_documents(documents)

        # áƒ”áƒ›áƒ‘áƒ”áƒ“áƒ˜áƒœáƒ’áƒ”áƒ‘áƒ˜áƒ¡ áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ
        print(">>> RAG áƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒ›áƒ˜áƒ¡ áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ (OpenAI)...")
        embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
        
        # áƒ•áƒ”áƒ¥áƒ¢áƒáƒ áƒ£áƒšáƒ˜ áƒ‘áƒáƒ–áƒ˜áƒ¡ áƒ¨áƒ”áƒ¥áƒ›áƒœáƒ áƒ“áƒ áƒ¨áƒ”áƒœáƒáƒ®áƒ•áƒ
        vector_store = Chroma.from_documents(texts, embeddings, persist_directory="chroma_db")
        vector_store.persist()
        
        # RAG Retriever-áƒ˜áƒ¡ áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ
        print(" RAG Retriever áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ— áƒ©áƒáƒ˜áƒ¢áƒ•áƒ˜áƒ áƒ—áƒ chroma_db-áƒ“áƒáƒœ.")
        
        # LLM-áƒ˜áƒ¡ áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ
        llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)
        
        # RetrievalQA Chain
        rag_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vector_store.as_retriever()
        )
        print(" RAG Chain áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ— áƒ¨áƒ”áƒ˜áƒ¥áƒ›áƒœáƒ.")

    except Exception as e:
        print(f"!!! RAG áƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒ›áƒ˜áƒ¡ áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {e}")
        rag_chain = None # áƒ—áƒ£ áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ áƒ•áƒ”áƒ  áƒ›áƒáƒ®áƒ”áƒ áƒ®áƒ“áƒ

# -------------------------------------------------------------
# 3. FastAPI áƒáƒáƒšáƒ˜áƒ™áƒáƒªáƒ˜áƒ áƒ“áƒ áƒ áƒáƒ£áƒ¢áƒ”áƒ‘áƒ˜
# -------------------------------------------------------------

app = FastAPI(title="GPT-RAG Chatbot API")

# áƒáƒáƒšáƒ˜áƒ™áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ“áƒáƒ¬áƒ§áƒ”áƒ‘áƒ˜áƒ¡áƒáƒ¡ RAG áƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒ›áƒ˜áƒ¡ áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ
@app.on_event("startup")
async def startup_event():
    init_rag_system()

# áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒ›áƒáƒ“áƒ”áƒšáƒ”áƒ‘áƒ˜
class ChatbotRequest(BaseModel):
    prompt: str
    user_id: str

class ChatbotResponse(BaseModel):
    status: str
    processed_prompt: str
    ai_response: str
    result_data: dict

# ğŸ›‘ áƒáƒ•áƒ¢áƒáƒ áƒ˜áƒ–áƒáƒªáƒ˜áƒ áƒ›áƒáƒ®áƒ¡áƒœáƒ˜áƒšáƒ˜áƒ, áƒ áƒáƒ“áƒ’áƒáƒœ áƒ˜áƒœáƒ¢áƒ”áƒ áƒ¤áƒ”áƒ˜áƒ¡áƒ˜ áƒ“áƒ API áƒ”áƒ áƒ—áƒ¡áƒ áƒ“áƒ áƒ˜áƒ›áƒáƒ•áƒ” áƒ“áƒáƒ›áƒ”áƒœáƒ–áƒ”áƒ.
@app.post("/process_query", response_model=ChatbotResponse, tags=["Public"])
async def process_query(request_data: ChatbotRequest):
    if not rag_chain:
        # áƒ—áƒ£ RAG áƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒ›áƒ áƒ•áƒ”áƒ  áƒ©áƒáƒ˜áƒ¢áƒ•áƒ˜áƒ áƒ—áƒ, áƒ“áƒáƒ‘áƒ áƒ£áƒœáƒ“áƒ”áƒ‘áƒ 500
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="RAG áƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒ›áƒ áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ¤áƒáƒ–áƒáƒ¨áƒ˜áƒ áƒáƒœ áƒ•áƒ”áƒ  áƒ›áƒáƒ®áƒ”áƒ áƒ®áƒ“áƒ áƒ›áƒ˜áƒ¡áƒ˜ áƒ©áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒ•áƒ.",
        )

    try:
        # RAG áƒ¥áƒáƒšáƒ˜áƒ¡ áƒ’áƒáƒ¨áƒ•áƒ”áƒ‘áƒ
        result = rag_chain.invoke({"query": request_data.prompt})
        ai_response = result.get('result', "áƒáƒáƒ¡áƒ£áƒ®áƒ˜ áƒ•áƒ”áƒ  áƒ˜áƒ¥áƒœáƒ áƒ’áƒ”áƒœáƒ”áƒ áƒ˜áƒ áƒ”áƒ‘áƒ£áƒšáƒ˜.")

        return ChatbotResponse(
            status="success",
            processed_prompt=f"áƒ—áƒ¥áƒ•áƒ”áƒœáƒ˜ áƒ›áƒáƒ—áƒ®áƒáƒ•áƒœáƒ áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ. áƒ¡áƒ˜áƒ’áƒ áƒ«áƒ”: {len(request_data.prompt)}.",
            ai_response=ai_response,
            result_data={},
        )
    except Exception as e:
        print(f"áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ RAG chain-áƒ˜áƒ¡ áƒ’áƒáƒ¨áƒ•áƒ”áƒ‘áƒ˜áƒ¡áƒáƒ¡: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"áƒ›áƒáƒ®áƒ“áƒ áƒ¨áƒ˜áƒ“áƒ áƒ¡áƒ”áƒ áƒ•áƒ”áƒ áƒ£áƒšáƒ˜ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {str(e)}",
        )

# áƒ¡áƒ¢áƒáƒ¢áƒ˜áƒ™áƒ£áƒ áƒ˜ áƒ¤áƒáƒ˜áƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒ›áƒáƒ›áƒ¡áƒáƒ®áƒ£áƒ áƒ”áƒ‘áƒ (HTML, CSS, JS)
# áƒ”áƒ¡ áƒáƒ áƒ˜áƒ¡ áƒ™áƒ áƒ˜áƒ¢áƒ˜áƒ™áƒ£áƒšáƒ˜ áƒœáƒáƒ¬áƒ˜áƒšáƒ˜, áƒ áƒáƒ›áƒ”áƒšáƒ˜áƒª áƒ£áƒ–áƒ áƒ£áƒœáƒ•áƒ”áƒšáƒ§áƒáƒ¤áƒ¡ áƒ˜áƒœáƒ¢áƒ”áƒ áƒ¤áƒ”áƒ˜áƒ¡áƒ˜áƒ¡ áƒ©áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒ•áƒáƒ¡.
app.mount("/", StaticFiles(directory=".", html=True), name="static")

# -------------------------------------------------------------
# 4. Uvicorn-áƒ˜áƒ¡ áƒ’áƒáƒ¨áƒ•áƒ”áƒ‘áƒ (áƒšáƒáƒ™áƒáƒšáƒ£áƒ áƒ˜ áƒ¢áƒ”áƒ¡áƒ¢áƒ˜áƒ áƒ”áƒ‘áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡)
# -------------------------------------------------------------

if __name__ == "__main__":
    # Render áƒ˜áƒ§áƒ”áƒœáƒ”áƒ‘áƒ¡ Start Command-áƒ¡, áƒáƒ›áƒ˜áƒ¢áƒáƒ› áƒ”áƒ¡ áƒœáƒáƒ¬áƒ˜áƒšáƒ˜ áƒ›áƒ®áƒáƒšáƒáƒ“ áƒšáƒáƒ™áƒáƒšáƒ£áƒ áƒáƒ“ áƒ˜áƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ¡.
    port = int(os.getenv("PORT", 8040))
    uvicorn.run(app, host="0.0.0.0", port=port)

import os
import requests
import json
import time
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
from pypdf import PdfReader
from typing import Optional

# áƒ“áƒáƒ›áƒáƒ¢áƒ”áƒ‘áƒ£áƒšáƒ˜ áƒ˜áƒ›áƒáƒáƒ áƒ¢áƒ”áƒ‘áƒ˜ áƒ¡áƒ¢áƒáƒ¢áƒ˜áƒ™áƒ£áƒ áƒ˜ áƒ¤áƒáƒ˜áƒšáƒ”áƒ‘áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡
from fastapi.responses import HTMLResponse
# ğŸ’¡ áƒ¡áƒáƒ­áƒ˜áƒ áƒáƒ áƒ¤áƒáƒ˜áƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒ£áƒ¡áƒáƒ¤áƒ áƒ—áƒ®áƒáƒ“ áƒ¬áƒáƒ¡áƒáƒ™áƒ˜áƒ—áƒ®áƒáƒ“ áƒœáƒ”áƒ‘áƒ˜áƒ¡áƒ›áƒ˜áƒ”áƒ  áƒ’áƒáƒ áƒ”áƒ›áƒáƒ¨áƒ˜
from pathlib import Path

# ğŸš€ .env áƒ¤áƒáƒ˜áƒšáƒ˜áƒ¡ áƒ©áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒ•áƒ
from dotenv import load_dotenv
load_dotenv()

# ğŸ”‘ áƒ’áƒáƒ¡áƒáƒ¦áƒ”áƒ‘áƒ”áƒ‘áƒ˜áƒ¡ áƒ¬áƒáƒ™áƒ˜áƒ—áƒ®áƒ•áƒ áƒ’áƒáƒ áƒ”áƒ›áƒáƒ¡ áƒªáƒ•áƒšáƒáƒ“áƒ”áƒ‘áƒ˜áƒ“áƒáƒœ
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# --- RAG áƒ˜áƒœáƒ¡áƒ¢áƒ áƒ£áƒ›áƒ”áƒœáƒ¢áƒ”áƒ‘áƒ˜áƒ¡ áƒ˜áƒ›áƒáƒáƒ áƒ¢áƒ˜ ---
RAG_TOOLS_AVAILABLE = False
try:
    if OPENAI_API_KEY:
        os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

        from langchain_openai import OpenAIEmbeddings
        from langchain_community.vectorstores import Chroma
        from langchain_core.documents import Document
        RAG_TOOLS_AVAILABLE = True
        print("âœ… RAG áƒ‘áƒ˜áƒ‘áƒšáƒ˜áƒáƒ—áƒ”áƒ™áƒ”áƒ‘áƒ˜ áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ— áƒ©áƒáƒ˜áƒ¢áƒ•áƒ˜áƒ áƒ—áƒ.")
    else:
        print("âŒ WARNING: OPENAI_API_KEY áƒ•áƒ”áƒ  áƒ˜áƒ¥áƒœáƒ áƒœáƒáƒáƒáƒ•áƒœáƒ˜. RAG áƒ¤áƒ£áƒœáƒ¥áƒªáƒ˜áƒ”áƒ‘áƒ˜ áƒ’áƒáƒ›áƒáƒ áƒ—áƒ£áƒšáƒ˜áƒ.")
except Exception as e:
    print(f"âŒ WARNING: RAG áƒ‘áƒ˜áƒ‘áƒšáƒ˜áƒáƒ—áƒ”áƒ™áƒ”áƒ‘áƒ˜áƒ¡ áƒ˜áƒ›áƒáƒáƒ áƒ¢áƒ˜áƒ¡ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒáƒ: {e}. RAG áƒ¤áƒ£áƒœáƒ¥áƒªáƒ˜áƒ”áƒ‘áƒ˜ áƒ’áƒáƒ›áƒáƒ áƒ—áƒ£áƒšáƒ˜áƒ.")

# --- áƒ™áƒáƒœáƒ¤áƒ˜áƒ’áƒ£áƒ áƒáƒªáƒ˜áƒ ---
OPENAI_MODEL_NAME = "gpt-4o-mini"
OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"
PERSONA_PDF_PATH = "prompt.pdf"
CHROMA_PATH = "chroma_db"

global_rag_retriever: Optional[Chroma.as_retriever] = None

# --- áƒ¤áƒ£áƒœáƒ¥áƒªáƒ˜áƒ áƒáƒ”áƒ áƒ¡áƒáƒœáƒ˜áƒ¡ PDF-áƒ“áƒáƒœ áƒ©áƒáƒ¡áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒáƒ“ ---
def load_persona_from_pdf(file_path: str) -> str:
    # ğŸ’¡ áƒ˜áƒ§áƒ”áƒœáƒ”áƒ‘áƒ¡ Path-áƒ¡ áƒ£áƒ¡áƒáƒ¤áƒ áƒ—áƒ®áƒáƒ”áƒ‘áƒ˜áƒ¡áƒáƒ—áƒ•áƒ˜áƒ¡
    DEFAULT_PERSONA = "áƒ—áƒ¥áƒ•áƒ”áƒœ áƒ®áƒáƒ áƒ— áƒ¡áƒáƒ¡áƒáƒ áƒ’áƒ”áƒ‘áƒšáƒ áƒáƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒœáƒ¢áƒ˜, áƒ áƒáƒ›áƒ”áƒšáƒ˜áƒª áƒáƒáƒ¡áƒ£áƒ®áƒáƒ‘áƒ¡ áƒ¥áƒáƒ áƒ—áƒ£áƒš áƒ”áƒœáƒáƒ–áƒ”."
    
    # áƒ¤áƒáƒ˜áƒšáƒ˜áƒ¡ áƒáƒ‘áƒ¡áƒáƒšáƒ£áƒ¢áƒ£áƒ áƒ˜ áƒ’áƒ–áƒ
    base_dir = Path(__file__).parent
    full_path = base_dir / file_path
    
    try:
        reader = PdfReader(full_path)
        text = "".join(page.extract_text() + "\n\n" for page in reader.pages if page.extract_text())
        if not text.strip():
            print(f"âŒ ERROR: PDF áƒ¤áƒáƒ˜áƒšáƒ˜ '{file_path}' áƒªáƒáƒ áƒ˜áƒ”áƒšáƒ˜áƒ. áƒ’áƒáƒ›áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ£áƒšáƒ˜áƒ áƒ“áƒ”áƒ¤áƒáƒšáƒ¢áƒ£áƒ áƒ˜ áƒáƒ”áƒ áƒ¡áƒáƒœáƒ.")
            return DEFAULT_PERSONA
        print(f"âœ… áƒáƒ”áƒ áƒ¡áƒáƒœáƒ˜áƒ¡ áƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜ áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ— áƒ©áƒáƒ˜áƒ¢áƒ•áƒ˜áƒ áƒ—áƒ {file_path}-áƒ“áƒáƒœ. áƒ¡áƒ˜áƒ’áƒ áƒ«áƒ”: {len(text.strip())} áƒ¡áƒ˜áƒ›áƒ‘áƒáƒšáƒ.")
        return text.strip()
    except Exception as e:
        print(f"âŒ ERROR: áƒáƒ”áƒ áƒ¡áƒáƒœáƒ˜áƒ¡ PDF-áƒ˜áƒ¡ áƒ¬áƒáƒ™áƒ˜áƒ—áƒ®áƒ•áƒ˜áƒ¡áƒáƒ¡ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {e}. áƒ’áƒáƒ›áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ£áƒšáƒ˜áƒ áƒ“áƒ”áƒ¤áƒáƒšáƒ¢áƒ£áƒ áƒ˜ áƒáƒ”áƒ áƒ¡áƒáƒœáƒ.")
        return DEFAULT_PERSONA

CUSTOM_PERSONA_TEXT = load_persona_from_pdf(PERSONA_PDF_PATH)

# --- FastAPI áƒáƒáƒšáƒ˜áƒ™áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ ---
app = FastAPI(title="OpenAI RAG API", version="1.0 - GPT Activated")

# --- Startup áƒšáƒáƒ’áƒ˜áƒ™áƒ: RAG áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ ---
@app.on_event("startup")
async def startup_event():
    global global_rag_retriever

    if not RAG_TOOLS_AVAILABLE:
        print("RAG áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ áƒ’áƒáƒ›áƒáƒ¢áƒáƒ•áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ.")
        return

    print(">>> RAG áƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒ›áƒ˜áƒ¡ áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ (OpenAI)...")
    
    # ğŸ’¡ áƒ˜áƒ§áƒ”áƒœáƒ”áƒ‘áƒ¡ Path-áƒ¡ ChromaDB-áƒ˜áƒ¡ áƒáƒ‘áƒ¡áƒáƒšáƒ£áƒ¢áƒ£áƒ áƒ˜ áƒ’áƒ–áƒ˜áƒ¡ áƒ›áƒ˜áƒ¡áƒáƒ¦áƒ”áƒ‘áƒáƒ“
    base_dir = Path(__file__).parent
    full_chroma_path = base_dir / CHROMA_PATH

    if full_chroma_path.exists():
        try:
            embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
            vector_store = Chroma(
                persist_directory=str(full_chroma_path),
                embedding_function=embeddings
            )
            global_rag_retriever = vector_store.as_retriever(search_kwargs={"k": 3})
            print(f"âœ… RAG Retriever áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ— áƒ©áƒáƒ˜áƒ¢áƒ•áƒ˜áƒ áƒ—áƒ {CHROMA_PATH}-áƒ“áƒáƒœ.")
        except Exception as e:
            print(f"âŒ ERROR: ChromaDB-áƒ˜áƒ¡ áƒ©áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒ•áƒ áƒ•áƒ”áƒ  áƒ›áƒáƒ®áƒ”áƒ áƒ®áƒ“áƒ: {e}. áƒ¨áƒ”áƒáƒ›áƒáƒ¬áƒ›áƒ”áƒ— OPENAI_API_KEY.")
    else:
        print(f"âš ï¸ WARNING: áƒ•áƒ”áƒ¥áƒ¢áƒáƒ áƒ£áƒšáƒ˜ áƒ‘áƒáƒ–áƒ {CHROMA_PATH} áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ. RAG áƒáƒ áƒáƒáƒ¥áƒ¢áƒ˜áƒ£áƒ áƒ˜áƒ. áƒ’áƒáƒ£áƒ¨áƒ•áƒ˜áƒ— 'python ingest.py' áƒ“áƒ áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒ”áƒ— chroma_db.")

# --- CORS Middleware áƒ“áƒáƒ›áƒáƒ¢áƒ”áƒ‘áƒ ---
origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- ğŸ’¡ ROOT áƒ”áƒœáƒ“áƒ¤áƒáƒ˜áƒœáƒ¢áƒ˜, áƒ áƒáƒ›áƒ”áƒšáƒ˜áƒª index.html-áƒ¡ áƒ”áƒ›áƒ¡áƒáƒ®áƒ£áƒ áƒ”áƒ‘áƒ ---
@app.get("/", response_class=HTMLResponse, include_in_schema=False)
async def read_index():
    """áƒáƒ‘áƒ áƒ£áƒœáƒ”áƒ‘áƒ¡ index.html-áƒ¡ áƒ›áƒ—áƒáƒ•áƒáƒ  áƒ›áƒ˜áƒ¡áƒáƒ›áƒáƒ áƒ—áƒ–áƒ”, áƒ˜áƒ§áƒ”áƒœáƒ”áƒ‘áƒ¡ áƒ£áƒ¡áƒáƒ¤áƒ áƒ—áƒ®áƒ áƒ’áƒ–áƒáƒ¡."""
    # ğŸ’¡ áƒ˜áƒ§áƒ”áƒœáƒ”áƒ‘áƒ¡ Path-áƒ¡ index.html-áƒ˜áƒ¡ áƒáƒ‘áƒ¡áƒáƒšáƒ£áƒ¢áƒ£áƒ áƒ˜ áƒ’áƒ–áƒ˜áƒ¡ áƒ›áƒ˜áƒ¡áƒáƒ¦áƒ”áƒ‘áƒáƒ“
    base_dir = Path(__file__).parent
    file_path = base_dir / "index.html"
    
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return HTMLResponse("<h1>Error 500: index.html not found!</h1>", status_code=500)
    except Exception as e:
        return HTMLResponse(f"<h1>Error loading index.html: {e}</h1>", status_code=500)


# áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒ›áƒáƒ“áƒ”áƒšáƒ”áƒ‘áƒ˜
class ChatbotRequest(BaseModel):
    prompt: str
    user_id: str

class ChatbotResponse(BaseModel):
    status: str
    processed_prompt: str
    ai_response: str
    result_data: dict

# --- OpenAI API-áƒ¡ áƒ’áƒáƒ›áƒáƒ«áƒáƒ®áƒ”áƒ‘áƒ (RAG áƒšáƒáƒ’áƒ˜áƒ™áƒ˜áƒ—) ---
def generate_openai_content(prompt: str) -> str:
    # (áƒ¤áƒ£áƒœáƒ¥áƒªáƒ˜áƒ˜áƒ¡ áƒ¨áƒ˜áƒ’áƒ—áƒáƒ•áƒ¡áƒ˜ áƒ áƒ©áƒ”áƒ‘áƒ áƒ˜áƒ’áƒ˜áƒ•áƒ”)
    if not OPENAI_API_KEY:
        return "ERROR: OPENAI API áƒ’áƒáƒ¡áƒáƒ¦áƒ”áƒ‘áƒ˜ áƒáƒ™áƒšáƒ˜áƒ áƒ’áƒáƒ áƒ”áƒ›áƒáƒ¡ áƒªáƒ•áƒšáƒáƒ“áƒ”áƒ‘áƒ¨áƒ˜."

    rag_context = ""
    is_rag_active = global_rag_retriever is not None

    if is_rag_active:
        try:
            docs: list[Document] = global_rag_retriever.invoke(prompt)
            context_text = "\n---\n".join([doc.page_content for doc in docs])

            rag_context = (
                f"áƒ’áƒáƒ›áƒáƒ˜áƒ§áƒ”áƒœáƒ”áƒ— áƒ¨áƒ”áƒ›áƒ“áƒ”áƒ’áƒ˜ áƒ™áƒáƒœáƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜ áƒáƒáƒ¡áƒ£áƒ®áƒ˜áƒ¡ áƒ’áƒáƒ¡áƒáƒªáƒ”áƒ›áƒáƒ“. áƒ—áƒ£ áƒáƒáƒ¡áƒ£áƒ®áƒ˜ áƒ›áƒáƒªáƒ”áƒ›áƒ£áƒš áƒ™áƒáƒœáƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ¨áƒ˜ áƒáƒ  áƒáƒ áƒ˜áƒ¡, "
                f"áƒ›áƒáƒ¨áƒ˜áƒœ áƒ£áƒáƒáƒ¡áƒ£áƒ®áƒ”áƒ— áƒ–áƒáƒ’áƒáƒ“áƒ˜ áƒªáƒáƒ“áƒœáƒ˜áƒ¡ áƒ¡áƒáƒ¤áƒ£áƒ«áƒ•áƒ”áƒšáƒ–áƒ”: \n\n--- DOCUMENTS ---\n{context_text}\n---"
            )
            print(f"ğŸ” RAG-áƒ›áƒ áƒ˜áƒáƒáƒ•áƒ {len(docs)} áƒ áƒ”áƒšáƒ”áƒ•áƒáƒœáƒ¢áƒ£áƒ áƒ˜ áƒ¤áƒ áƒáƒ’áƒ›áƒ”áƒœáƒ¢áƒ˜.")

        except Exception as e:
            print(f"âŒ ERROR: RAG Retrieval-áƒ˜áƒ¡ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {e}")
            rag_context = ""

    final_user_prompt = f"{rag_context}\n\náƒ›áƒáƒ›áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒšáƒ˜áƒ¡ áƒ¨áƒ”áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ: {prompt}"

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {OPENAI_API_KEY}"
    }

    payload = {
        "model": OPENAI_MODEL_NAME,
        "messages": [
            {"role": "system", "content": f"{CUSTOM_PERSONA_TEXT}"},
            {"role": "user", "content": final_user_prompt}
        ]
    }

    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = requests.post(
                OPENAI_API_URL,
                headers=headers,
                data=json.dumps(payload),
                timeout=30
            )

            if response.status_code >= 400:
                try:
                    error_detail = response.json()
                    return f"ERROR: OpenAI API-áƒ› áƒ“áƒáƒáƒ‘áƒ áƒ£áƒœáƒ {response.status_code} áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ. áƒ“áƒ”áƒ¢áƒáƒšáƒ”áƒ‘áƒ˜: {error_detail.get('error', {}).get('message', 'áƒ“áƒ”áƒ¢áƒáƒšáƒ£áƒ áƒ˜ áƒ¨áƒ”áƒ¢áƒ§áƒáƒ‘áƒ˜áƒœáƒ”áƒ‘áƒ áƒ•áƒ”áƒ  áƒ›áƒ˜áƒ˜áƒ¦áƒ”áƒ¡.')}"
                except json.JSONDecodeError:
                    return f"ERROR: OpenAI API-áƒ› áƒ“áƒáƒáƒ‘áƒ áƒ£áƒœáƒ {response.status_code} áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ. áƒáƒáƒ¡áƒ£áƒ®áƒ˜ áƒáƒ  áƒáƒ áƒ˜áƒ¡ JSON-áƒ¨áƒ˜."

            response.raise_for_status()
            result = response.json()

            if result.get('choices'):
                return result['choices'][0]['message']['content']

            return f"OpenAI API-áƒ› áƒ“áƒáƒáƒ‘áƒ áƒ£áƒœáƒ áƒáƒ áƒáƒ¡áƒ¢áƒáƒœáƒ“áƒáƒ áƒ¢áƒ£áƒšáƒ˜ áƒáƒáƒ¡áƒ£áƒ®áƒ˜."

        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt
                print(f"âš ï¸ Warning: OpenAI API-áƒ¡áƒ—áƒáƒœ áƒ“áƒáƒ™áƒáƒ•áƒ¨áƒ˜áƒ áƒ”áƒ‘áƒ áƒ•áƒ”áƒ  áƒ›áƒáƒ®áƒ”áƒ áƒ®áƒ“áƒ. áƒªáƒ“áƒ {attempt + 1}/{max_retries}. áƒšáƒáƒ“áƒ˜áƒœáƒ˜ {wait_time} áƒ¬áƒ›.")
                time.sleep(wait_time)
            else:
                return f"ERROR: OpenAI API-áƒ¡áƒ—áƒáƒœ áƒ“áƒáƒ™áƒáƒ•áƒ¨áƒ˜áƒ áƒ”áƒ‘áƒ áƒ•áƒ”áƒ  áƒ›áƒáƒ®áƒ”áƒ áƒ®áƒ“áƒ. áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {e}"
        except Exception as e:
            return f"ERROR: áƒ›áƒáƒ£áƒšáƒáƒ“áƒœáƒ”áƒšáƒ˜ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {e}"

    return "ERROR: áƒáƒáƒ¡áƒ£áƒ®áƒ˜ áƒ•áƒ”áƒ  áƒ˜áƒ¥áƒœáƒ áƒ’áƒ”áƒœáƒ”áƒ áƒ˜áƒ áƒ”áƒ‘áƒ£áƒšáƒ˜."


@app.post("/process_query", response_model=ChatbotResponse, tags=["Secured"])
async def process_query(
    request_data: ChatbotRequest,
):
    # (áƒ¤áƒ£áƒœáƒ¥áƒªáƒ˜áƒ˜áƒ¡ áƒ¨áƒ˜áƒ’áƒ—áƒáƒ•áƒ¡áƒ˜ áƒ áƒ©áƒ”áƒ‘áƒ áƒ˜áƒ’áƒ˜áƒ•áƒ”)
    openai_response = generate_openai_content(request_data.prompt)

    response_data = {
        "user": request_data.user_id,
        "length": len(request_data.prompt),
        "is_rag_active": global_rag_retriever is not None,
        "openai_model": OPENAI_MODEL_NAME
    }

    return ChatbotResponse(
        status="success",
        processed_prompt=f"áƒ—áƒ¥áƒ•áƒ”áƒœáƒ˜ áƒ›áƒáƒ—áƒ®áƒáƒ•áƒœáƒ áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ. áƒ¡áƒ˜áƒ’áƒ áƒ«áƒ”: {len(request_data.prompt)}.",
        ai_response=openai_response,
        result_data=response_data,
    )

if __name__ == "__main__":
    PORT = int(os.getenv("PORT", 8040))
    print(f"ğŸš€ áƒáƒáƒšáƒ˜áƒ™áƒáƒªáƒ˜áƒ áƒ˜áƒ¨áƒ•áƒ”áƒ‘áƒ: http://0.0.0.0:{PORT}")
    uvicorn.run(app, host="0.0.0.0", port=PORT)
